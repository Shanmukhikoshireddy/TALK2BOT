# ğŸ¤ Voice Chatbot with Emotion Detection (English + à°¤à±†à°²à±à°—à±)

A web-based AI voice chatbot that can:
- ğŸ™ï¸ Accept voice input
- ğŸ§  Detect the user's emotion from speech
- ğŸ—£ï¸ Transcribe audio to text (Telugu & English)
- ğŸ¤– Generate intelligent responses using Gemini AI
- ğŸ” Let the user edit and regenerate responses
- ğŸ”Š Speak the response back to the user

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                      # Main Flask backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Frontend UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ response*.mp3           # Auto-generated response audios
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ input.webm/.wav         # Uploaded and converted audio
â”œâ”€â”€ emotion_model.h5           # Pre-trained emotion classification model
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸš€ Features

- ğŸ™ï¸ **Voice Recording**: Record your speech directly from the browser.
- ğŸ” **Speech-to-Text**: Transcribes using Google Speech Recognition (supports Telugu & English).
- ğŸ§  **Emotion Detection**: Detects emotion from audio using a CNN model.
- ğŸ¤– **Gemini AI Integration**: Generates responses using Google Gemini API (multilingual).
- âœï¸ **Editable Messages**: Edit your question and regenerate a new response.
- ğŸ”Š **Voice Output**: Converts the AI response into speech using gTTS.
- ğŸŒ **Language Detection**: Automatically detects whether you're speaking Telugu or English.

---

## ğŸ§ª Technologies Used

- Python (Flask)
- HTML, CSS, JavaScript
- [Google Gemini API](https://ai.google.dev/)
- Google Speech Recognition API
- gTTS (Google Text-to-Speech)
- Pydub + FFmpeg for audio conversion
- Librosa for audio feature extraction
- Keras/TensorFlow for emotion classification

---

## ğŸ“¦ Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/voice-chatbot-emotion.git
cd voice-chatbot-emotion
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Install system dependencies**

Make sure `ffmpeg` is installed:

```bash
# On Windows: install via ffmpeg.org or add to PATH
# On Ubuntu:
sudo apt update
sudo apt install ffmpeg
```

4. **Add Gemini API Key**

Update this line in `app.py` with your key:

```python
genai.configure(api_key="YOUR_API_KEY")
```

5. **Run the Flask app**

```bash
python app.py
```

Open in browser: [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸ§  Emotion Detection Model

- Input: Audio clip (3 seconds)
- Extracts MFCC features using `librosa`
- CNN model trained on labeled emotion audio dataset
- Output: Predicted emotion (e.g., happy, sad, angry...)

Model file: `emotion_model.h5`

---

## ğŸ–¼ï¸ Screenshot

![screenshot](Output.png)

---

## ğŸ› ï¸ Troubleshooting

| Problem | Solution |
|--------|----------|
| âŒ Audio not recording | Check browser permissions |
| âŒ "Couldn't detect language" | Ensure you're speaking clearly; fallback is English |
| âŒ Regeneration error | Ensure API key is set and fix typo in `/regenerate` |
| âŒ FFmpeg errors | Install `ffmpeg` and add it to your system PATH |

---

## ğŸ“Œ TODO (Optional Improvements)

- Add Whisper model for better transcription
- Emotion-based avatar reactions (3D/2D)
- Save chat history
- Real-time audio streaming
- Dark/light theme switch

---

## ğŸ“„ License

This project is for educational and personal use. Contact the author for commercial use.

---

## ğŸ™Œ Acknowledgements

- Google Gemini & gTTS
- SpeechRecognition & Librosa
- TensorFlow/Keras
- Inspiration from emotion-aware interfaces

---
